{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d041ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educated-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File processing\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data display \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "# Machine learning\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import linalg as LAtorch\n",
    "from numpy import linalg as LAnumpy\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "# Setting device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac13c5",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465431e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 400\n",
    "BATCH_SIZE = 10\n",
    "NB_BINS = 1280\n",
    "EMBEDDING_SIZE = 3 # Euclidean 3D space\n",
    "LEARNING_RATE = 0.001\n",
    "SEED = 9828937\n",
    "LAMBDA_KABSCH = 0.1\n",
    "TRAIN_DATASET_SIZE = 800\n",
    "TEST_DATASET_SIZE = 200\n",
    "\n",
    "# Trussart analysis dataset constants\n",
    "TRUSSART_HIC_PATH = '../../../../../../experiments/data/trussart/hic_matrices/150_TADlike_alpha_50_set0.mat'\n",
    "TRUSSART_STRUCTURES_PATH = '../../../../../../experiments/data/trussart/structure_matrices/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc7277",
   "metadata": {},
   "source": [
    "# Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26605809",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4c9f8",
   "metadata": {},
   "source": [
    "# Trussart analysis dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d412f446",
   "metadata": {},
   "source": [
    "## Hic matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naval-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "trussart_hic = np.loadtxt(TRUSSART_HIC_PATH, dtype='f', delimiter='\\t')\n",
    "scaler = MinMaxScaler()\n",
    "trussart_hic = scaler.fit_transform(trussart_hic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b876b",
   "metadata": {},
   "source": [
    "## Structure matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43eefd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trussart_structures = []\n",
    "\n",
    "file_list = os.listdir(TRUSSART_STRUCTURES_PATH)\n",
    "file_list = filter(lambda f: f.endswith('.xyz'), file_list)\n",
    "\n",
    "for file_name in file_list:\n",
    "    current_trussart_structure = np.loadtxt(TRUSSART_STRUCTURES_PATH + file_name, dtype='f', delimiter='\\t')\n",
    "    current_trussart_structure = current_trussart_structure[:,1:]\n",
    "    trussart_structures.append(current_trussart_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-gnome",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debceb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab last 4 digits of the file txt name:\n",
    "def last_4digits(x):\n",
    "    return(x[-8:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820ee0f",
   "metadata": {},
   "source": [
    "### Hic matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdcfc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transfer_learning_hics = []\n",
    "\n",
    "file_list = os.listdir('../../../../data/synthetic_random/train/hic_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_train_transfer_learning_hic = np.loadtxt('../../../../data/synthetic_random/train/hic_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    train_transfer_learning_hics.append(current_train_transfer_learning_hic)\n",
    "    \n",
    "train_transfer_learning_hics = np.asarray(train_transfer_learning_hics)[:,:NB_BINS, :NB_BINS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3704005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transfer_learning_hics = []\n",
    "\n",
    "file_list = os.listdir('../../../../data/synthetic_random/test/hic_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_test_transfer_learning_hic = np.loadtxt('../../../../data/synthetic_random/test/hic_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    test_transfer_learning_hics.append(current_test_transfer_learning_hic)\n",
    "    \n",
    "test_transfer_learning_hics = np.asarray(test_transfer_learning_hics)[:,:NB_BINS, :NB_BINS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e0673",
   "metadata": {},
   "source": [
    "### Structure matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbfce60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transfer_learning_structures = []\n",
    "\n",
    "file_list = os.listdir('../../../../data/synthetic_random/train/structure_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_train_transfer_learning_structure = \\\n",
    "        np.loadtxt('../../../../data/synthetic_random/train/structure_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    train_transfer_learning_structures.append(current_train_transfer_learning_structure)\n",
    "    \n",
    "train_transfer_learning_structures = np.asarray(train_transfer_learning_structures)[:,:NB_BINS,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a41608",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transfer_learning_structures = []\n",
    "\n",
    "file_list = os.listdir('../../../../data/synthetic_random/test/structure_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_test_transfer_learning_structure = \\\n",
    "        np.loadtxt('../../../../data/synthetic_random/test/structure_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    test_transfer_learning_structures.append(current_test_transfer_learning_structure)\n",
    "    \n",
    "test_transfer_learning_structures = np.asarray(test_transfer_learning_structures)[:,:NB_BINS,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24328a71",
   "metadata": {},
   "source": [
    "### Distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "182f8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transfer_learning_distances = []\n",
    "\n",
    "file_list = os.listdir('../../../../data/synthetic_random/train/distance_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_train_transfer_learning_distance = \\\n",
    "            np.loadtxt('../../../../data/synthetic_random/train/distance_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    train_transfer_learning_distances.append(current_train_transfer_learning_distance)\n",
    "    \n",
    "train_transfer_learning_distances = np.asarray(train_transfer_learning_distances)[:,:NB_BINS,:NB_BINS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeebfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transfer_learning_distances = []\n",
    "\n",
    "file_list = os.listdir('../../../../data/synthetic_random/test/distance_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_test_transfer_learning_distance = \\\n",
    "            np.loadtxt('../../../../data/synthetic_random/test/distance_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    test_transfer_learning_distances.append(current_test_transfer_learning_distance)\n",
    "    \n",
    "test_transfer_learning_distances = np.asarray(test_transfer_learning_distances)[:,:NB_BINS,:NB_BINS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0a949",
   "metadata": {},
   "source": [
    "### Final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cfddc",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ecf83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regulation-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(VanillaDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        if is_training:\n",
    "            return ['non_ae_synthetic_random_linear_train_data.txt']\n",
    "        else:\n",
    "            return ['non_ae_synthetic_random_linear_test_data.txt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "        if is_training:\n",
    "            dataset_size = TRAIN_DATASET_SIZE\n",
    "        else:\n",
    "            dataset_size = TEST_DATASET_SIZE\n",
    "        \n",
    "        for i in tqdm(range(dataset_size)):\n",
    "            \n",
    "            if is_training:\n",
    "                transfer_learning_hic = train_transfer_learning_hics[i]\n",
    "                transfer_learning_structure = train_transfer_learning_structures[i]\n",
    "                transfer_learning_distance_matrix = train_transfer_learning_distances[i]\n",
    "            else:\n",
    "                transfer_learning_hic = test_transfer_learning_hics[i]\n",
    "                transfer_learning_structure = test_transfer_learning_structures[i]\n",
    "                transfer_learning_distance_matrix = test_transfer_learning_distances[i]\n",
    "               \n",
    "            hic_matrix = torch.FloatTensor(transfer_learning_hic)\n",
    "            structure_matrix = torch.FloatTensor(transfer_learning_structure)\n",
    "            distance_matrix = torch.FloatTensor(transfer_learning_distance_matrix)\n",
    "\n",
    "            data = Data(hic_matrix=hic_matrix, structure_matrix=structure_matrix, distance_matrix=distance_matrix)\n",
    "            data_list.append(data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incredible-reform",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 28021.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VanillaDataset('../')\n",
    "train_dataset = train_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "considered-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(train_dataset)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b9ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6adbb",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a45875f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd917ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 5218.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_dataset = VanillaDataset('../')\n",
    "test_dataset = test_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d6319b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = len(test_dataset)\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ede05c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-invite",
   "metadata": {},
   "source": [
    "# Linear Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e7a7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.linear_encoder_layer_1 = torch.nn.Linear(NB_BINS, int(NB_BINS/2.0))\n",
    "        self.linear_encoder_layer_2 = torch.nn.Linear(int(NB_BINS/2.0), int(NB_BINS/4.0))\n",
    "        self.linear_encoder_layer_3 = torch.nn.Linear(int(NB_BINS/4.0), EMBEDDING_SIZE)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.reshape(x, (BATCH_SIZE, NB_BINS, NB_BINS))\n",
    "        \n",
    "        z = self.linear_encoder_layer_1(x)\n",
    "        z = F.relu(z)\n",
    "        z = self.linear_encoder_layer_2(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.linear_encoder_layer_3(z)\n",
    "        z = F.relu(z)\n",
    "        z = centralize_and_normalize_torch(z)\n",
    "        \n",
    "        w = torch.cdist(z, z, p=2)\n",
    "        \n",
    "        return z, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771473b",
   "metadata": {},
   "source": [
    "# Structure analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74381471",
   "metadata": {},
   "source": [
    "### Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10db24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize_torch(z):\n",
    "    return z - torch.repeat_interleave(torch.reshape(torch.mean(z, axis=1), (-1,1,EMBEDDING_SIZE)), NB_BINS, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2056afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_torch(z):\n",
    "    \n",
    "    norms = LAtorch.norm(z, 2, dim=2)\n",
    "    max_norms, _ = torch.max(norms, axis=1)\n",
    "    max_norms = torch.reshape(max_norms, (BATCH_SIZE,1,1))\n",
    "    max_norms = torch.repeat_interleave(max_norms, NB_BINS, dim=1)\n",
    "    max_norms = torch.repeat_interleave(max_norms, EMBEDDING_SIZE, dim=2)\n",
    "    max_norms[max_norms == 0] = 1\n",
    "    \n",
    "    return z / max_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba06874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize_and_normalize_torch(z):\n",
    "    \n",
    "    # Translate\n",
    "    z = centralize_torch(z)\n",
    "    \n",
    "    # Scale\n",
    "    z = normalize_torch(z)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e764b0",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30307ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize_numpy(z):\n",
    "    return z - np.mean(z, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6688fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numpy(z):\n",
    "    \n",
    "    norm = LAnumpy.norm(z, 2, axis=1)\n",
    "    max_norm = np.max(norm, axis=0)\n",
    "    if max_norm == 0:\n",
    "        max_norm = 1\n",
    "    \n",
    "    return z / max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87f22cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize_and_normalize_numpy(z):\n",
    "    \n",
    "    # Translate\n",
    "    z = centralize_numpy(z)\n",
    "    \n",
    "    # Scale\n",
    "    z = normalize_numpy(z)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e885c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kabsch_superimposition_numpy(pred_structure, true_structure):\n",
    "    \n",
    "    # Centralize and normalize to unit ball\n",
    "    pred_structure_unit_ball = centralize_and_normalize_numpy(pred_structure)\n",
    "    true_structure_unit_ball = centralize_and_normalize_numpy(true_structure)\n",
    "    \n",
    "    # Rotation (solution for the constrained orthogonal Procrustes problem, subject to det(R) = 1)\n",
    "    m = np.matmul(np.transpose(true_structure_unit_ball), pred_structure_unit_ball)\n",
    "    u, s, vh = np.linalg.svd(m)\n",
    "    \n",
    "    d = np.sign(np.linalg.det(np.matmul(u, vh)))\n",
    "    a = np.eye(EMBEDDING_SIZE)\n",
    "    a[-1,-1] = d\n",
    "    \n",
    "    r = np.matmul(np.matmul(u, a), vh)\n",
    "    \n",
    "    pred_structure_unit_ball = np.transpose(np.matmul(r, np.transpose(pred_structure_unit_ball)))\n",
    "    \n",
    "    return pred_structure_unit_ball, true_structure_unit_ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18470850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kabsch_distance_numpy(pred_structure, true_structure):\n",
    "    \n",
    "    pred_structure_unit_ball, true_structure_unit_ball = kabsch_superimposition_numpy(pred_structure, true_structure)\n",
    "    \n",
    "    # Structure comparison\n",
    "    d = np.mean(np.sum(np.square(pred_structure_unit_ball - true_structure_unit_ball), axis=1))\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9093e7e",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d59400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kabsch_loss_fct(pred_structure, true_structure):\n",
    "    \n",
    "    # NOTE: the two input structures should already be centralized and normalized\n",
    "    \n",
    "    m = torch.matmul(torch.transpose(true_structure, 1, 2), pred_structure)\n",
    "    u, s, vh = torch.linalg.svd(m)\n",
    "    \n",
    "    d = torch.sign(torch.linalg.det(torch.matmul(u, vh)))\n",
    "    a = torch.eye(EMBEDDING_SIZE).reshape((1, EMBEDDING_SIZE, EMBEDDING_SIZE)).repeat_interleave(BATCH_SIZE, dim=0)\n",
    "    a[:,-1,-1] = d\n",
    "    \n",
    "    r = torch.matmul(torch.matmul(u, a), vh)\n",
    "    \n",
    "    pred_structure = torch.transpose(torch.matmul(r, torch.transpose(pred_structure, 1, 2)), 1, 2)\n",
    "    \n",
    "    return torch.mean(torch.sum(torch.square(pred_structure - true_structure), axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbdc7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_loss_fct = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75b2b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trussart_test_kabsch_loss():\n",
    "    \n",
    "    torch_trussart_hic = torch.FloatTensor(trussart_hic[:NB_BINS, :NB_BINS])\n",
    "    torch_trussart_hic = torch.reshape(torch_trussart_hic, (1, NB_BINS, NB_BINS))\n",
    "    torch_trussart_hic = torch.repeat_interleave(torch_trussart_hic, BATCH_SIZE, 0)\n",
    "    \n",
    "    trussart_pred_structure, _ = model(torch_trussart_hic)\n",
    "    trussart_pred_structure = trussart_pred_structure.detach().numpy()[0]\n",
    "    \n",
    "    kabsch_distances = []\n",
    "    for true_structure in trussart_structures:\n",
    "        kabsch_distances.append(kabsch_distance_numpy(trussart_pred_structure, true_structure[:NB_BINS, :]))\n",
    "        \n",
    "    return np.mean(kabsch_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-prerequisite",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "contemporary-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52b37ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.legend([matplotlib.lines.Line2D([0], [0], color=\"c\", lw=4),\n",
    "                matplotlib.lines.Line2D([0], [0], color=\"b\", lw=4),\n",
    "                matplotlib.lines.Line2D([0], [0], color=\"k\", lw=4)], \n",
    "               ['max-gradient', 'mean-gradient', 'zero-gradient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "artificial-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_structure, pred_distance = model(data.hic_matrix)\n",
    "        \n",
    "        true_hic = data.hic_matrix.to(device)\n",
    "        \n",
    "        true_structure = data.structure_matrix.to(device)\n",
    "        true_structure = torch.reshape(true_structure, (BATCH_SIZE, NB_BINS, EMBEDDING_SIZE))\n",
    "        \n",
    "        pred_distance = torch.reshape(pred_distance, (BATCH_SIZE*NB_BINS, NB_BINS))\n",
    "        true_distance = data.distance_matrix.to(device)\n",
    "        \n",
    "        # Kabsch loss\n",
    "        kabsch_loss = kabsch_loss_fct(pred_structure, true_structure)\n",
    "        \n",
    "        # Distance loss \n",
    "        distance_loss = distance_loss_fct(pred_distance, true_distance)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = LAMBDA_KABSCH * kabsch_loss + distance_loss\n",
    "        \n",
    "#         with torch.autograd.detect_anomaly():\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        \n",
    "        # Plot grad flow\n",
    "#         plot_grad_flow(model.named_parameters())\n",
    "        \n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "operating-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    true_hics = []\n",
    "    \n",
    "    pred_structures = []\n",
    "    true_structures = []\n",
    "    \n",
    "    pred_distances = []\n",
    "    true_distances = []\n",
    "    \n",
    "    kabsch_losses = []\n",
    "    distance_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            \n",
    "            pred_structure, pred_distance = model(data.hic_matrix)\n",
    "            \n",
    "            pred_structure = pred_structure.detach().cpu()\n",
    "            pred_distance = pred_distance.detach().cpu()\n",
    "            \n",
    "            pred_distance = torch.reshape(pred_distance, (BATCH_SIZE*NB_BINS, NB_BINS))\n",
    "            \n",
    "            true_hic = data.hic_matrix.detach().cpu()\n",
    "            true_structure = data.structure_matrix.detach().cpu()\n",
    "            true_distance = data.distance_matrix.detach().cpu()\n",
    "            \n",
    "            true_structure = torch.reshape(true_structure, (BATCH_SIZE, NB_BINS, EMBEDDING_SIZE))\n",
    "            \n",
    "            # Kabsch loss\n",
    "            kabsch_loss = kabsch_loss_fct(pred_structure, true_structure).numpy()\n",
    "            kabsch_losses.append(kabsch_loss)\n",
    "            \n",
    "            # Distance \n",
    "            distance_loss = distance_loss_fct(pred_distance, true_distance).numpy()\n",
    "            distance_losses.append(distance_loss)\n",
    "            \n",
    "            # To numpy\n",
    "            true_hic = true_hic.numpy()\n",
    "            \n",
    "            pred_structure = pred_structure.numpy()\n",
    "            true_structure = true_structure.numpy()\n",
    "            \n",
    "            pred_distance = pred_distance.numpy()\n",
    "            true_distance = true_distance.numpy()\n",
    "            \n",
    "            # Store results\n",
    "            true_hics.append(true_hic)\n",
    "            \n",
    "            pred_structures.append(pred_structure)\n",
    "            true_structures.append(true_structure)\n",
    "            \n",
    "            pred_distances.append(pred_distance)\n",
    "            true_distances.append(true_distance)\n",
    "    \n",
    "    # Format results\n",
    "    true_hics = np.vstack(true_hics)\n",
    "    \n",
    "    pred_structures = np.vstack(pred_structures)\n",
    "    true_structures = np.vstack(true_structures)\n",
    "    \n",
    "    pred_distances = np.vstack(pred_distances)\n",
    "    true_distances = np.vstack(true_distances)\n",
    "    \n",
    "    # Compute mean losses\n",
    "    mean_kabsch_loss = np.mean(np.asarray(kabsch_losses).flatten())\n",
    "    mean_distance_loss = np.mean(np.asarray(distance_losses).flatten())\n",
    "    \n",
    "    \n",
    "    return mean_kabsch_loss, mean_distance_loss, true_hics, \\\n",
    "            pred_structures, true_structures, pred_distances, true_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sacred-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 001, Tr K: 0.0855, Tr D: 0.0631, Te K: 0.0839, Te D: 0.0603\n",
      "E: 002, Tr K: 0.0765, Tr D: 0.0547, Te K: 0.0759, Te D: 0.0538\n",
      "E: 003, Tr K: 0.0691, Tr D: 0.0321, Te K: 0.0680, Te D: 0.0305\n",
      "E: 004, Tr K: 0.0628, Tr D: 0.0276, Te K: 0.0619, Te D: 0.0267\n",
      "E: 005, Tr K: 0.0576, Tr D: 0.0238, Te K: 0.0568, Te D: 0.0230\n",
      "E: 006, Tr K: 0.0548, Tr D: 0.0223, Te K: 0.0544, Te D: 0.0220\n",
      "E: 007, Tr K: 0.0518, Tr D: 0.0186, Te K: 0.0510, Te D: 0.0178\n",
      "E: 008, Tr K: 0.0515, Tr D: 0.0175, Te K: 0.0513, Te D: 0.0170\n",
      "E: 009, Tr K: 0.0494, Tr D: 0.0170, Te K: 0.0488, Te D: 0.0162\n",
      "E: 010, Tr K: 0.0510, Tr D: 0.0182, Te K: 0.0503, Te D: 0.0170\n",
      "E: 011, Tr K: 0.0473, Tr D: 0.0171, Te K: 0.0467, Te D: 0.0158\n",
      "E: 012, Tr K: 0.0495, Tr D: 0.0166, Te K: 0.0490, Te D: 0.0158\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3233a7d70d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-a8a1e503a356>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#         with torch.autograd.detect_anomaly():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_kabsch_losses_all_epochs = []\n",
    "train_distance_losses_all_epochs = []\n",
    "\n",
    "test_kabsch_losses_all_epochs = []\n",
    "test_distance_losses_all_epochs = []\n",
    "\n",
    "losses = []\n",
    "\n",
    "trussart_test_kabsch_losses_all_epochs = []\n",
    "\n",
    "for epoch in range(1, NB_EPOCHS+1):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    \n",
    "    ### Training\n",
    "    train_mean_kabsch_loss, train_mean_distance_loss, train_true_hics, \\\n",
    "        train_pred_structures, train_true_structures, train_pred_distances, \\\n",
    "            train_true_distances = evaluate(train_loader) \n",
    "    \n",
    "    # Store results\n",
    "    train_kabsch_losses_all_epochs.append(train_mean_kabsch_loss)    \n",
    "    train_distance_losses_all_epochs.append(train_mean_distance_loss)\n",
    "    \n",
    "    ### Testing\n",
    "    test_mean_kabsch_loss, test_mean_distance_loss, test_true_hics, \\\n",
    "        test_pred_structures, test_true_structures, test_pred_distances, \\\n",
    "            test_true_distances = evaluate(test_loader) \n",
    "    \n",
    "    ### Trussart test\n",
    "#     trussart_test_kabsch_loss = compute_trussart_test_kabsch_loss()\n",
    "    \n",
    "    # Store results\n",
    "    test_kabsch_losses_all_epochs.append(test_mean_kabsch_loss)    \n",
    "    test_distance_losses_all_epochs.append(test_mean_distance_loss)\n",
    "    \n",
    "#     trussart_test_kabsch_losses_all_epochs.append(trussart_test_kabsch_loss)\n",
    "    \n",
    "    print('E: {:03d}, Tr K: {:.4f}, Tr D: {:.4f}, Te K: {:.4f}, Te D: {:.4f}'.format(\\\n",
    "        epoch, train_mean_kabsch_loss, train_mean_distance_loss, \\\n",
    "            test_mean_kabsch_loss, test_mean_distance_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfeae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, label='Losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_kabsch_losses_all_epochs, label='Train Kabsch')\n",
    "plt.plot(test_kabsch_losses_all_epochs, label='Test Kabsch')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(test_kabsch_losses_all_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0b665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_distance_losses_all_epochs, label='Train Dist')\n",
    "plt.plot(test_distance_losses_all_epochs, label='Test Dist')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(test_distance_losses_all_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(trussart_test_kabsch_losses_all_epochs, label='Test Trussart Kabsch')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce10e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(trussart_test_kabsch_losses_all_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfff6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(20,10))\n",
    "\n",
    "axs.plot(range(1,NB_EPOCHS+1), np.asarray(train_distance_losses_all_epochs), \n",
    "         label=r'Training: $\\mathcal{L}_d$', color='red', linewidth=3)\n",
    "axs.plot(range(1,NB_EPOCHS+1), np.asarray(test_distance_losses_all_epochs), \n",
    "         label=r'Testing: $\\mathcal{L}_d$', color='red', linestyle='dashed', linewidth=3)\n",
    "\n",
    "axs.plot(range(1,NB_EPOCHS+1), LAMBDA_KABSCH* np.asarray(test_kabsch_losses_all_epochs), \n",
    "         label=r'Training: $\\lambda_k \\mathcal{L}_k$', color='blue', linewidth=3)\n",
    "axs.plot(range(1,NB_EPOCHS+1), LAMBDA_KABSCH* np.asarray(train_kabsch_losses_all_epochs), \n",
    "         label=r'Testing: $\\lambda_k \\mathcal{L}_k$', color='blue', linestyle='dashed', linewidth=3)\n",
    "\n",
    "axs.set_xlabel('Number of epochs', fontsize = 35)\n",
    "axs.set_ylabel('Loss value', fontsize = 35)\n",
    "plt.legend(fontsize=35, loc=(0.65, 0.55))\n",
    "\n",
    "axs.set_title('Train/Test Distance and Kabsch loss values', \n",
    "              size=40)\n",
    "\n",
    "axs.set_ylim(0, 0.020)\n",
    "axs.set_xlim(1, NB_EPOCHS+1)\n",
    "\n",
    "axs.tick_params(axis='both', which='major', labelsize=30, width=4)\n",
    "\n",
    "l = list(range(0, NB_EPOCHS+1, 5))\n",
    "l[0] = 1\n",
    "plt.xticks(ticks=l, labels=l)\n",
    "\n",
    "plt.savefig('synthetic_random_linear_train_test_losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a57c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16763.11364006996\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52a3fb",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kabsch_distances = []\n",
    "\n",
    "for graph_index in range(test_size):\n",
    "\n",
    "    test_true_structure = test_true_structures[graph_index,:,:]\n",
    "    test_pred_structure = test_pred_structures[graph_index,:,:]\n",
    "    \n",
    "    d = kabsch_distance_numpy(test_pred_structure, test_true_structure)\n",
    "    kabsch_distances.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_TESTED = np.argmin(kabsch_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f29f0",
   "metadata": {},
   "source": [
    "### Test distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55267a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15,15))\n",
    "\n",
    "ground_truth_matrix = test_true_distances[GRAPH_TESTED*NB_BINS:GRAPH_TESTED*NB_BINS+NB_BINS, :]\n",
    "axes[0].imshow(ground_truth_matrix, cmap='hot', interpolation='nearest')\n",
    "\n",
    "reconstruction_matrix = test_pred_distances[GRAPH_TESTED*NB_BINS:GRAPH_TESTED*NB_BINS+NB_BINS, :]\n",
    "axes[1].imshow(reconstruction_matrix, cmap='hot', interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ddd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "ground_truth_matrix = test_true_distances[GRAPH_TESTED*NB_BINS:GRAPH_TESTED*NB_BINS+NB_BINS, :]\n",
    "axs.imshow(ground_truth_matrix, cmap='hot', interpolation='nearest')\n",
    "axs.tick_params(axis='both', which='major', labelsize=30, width=4)\n",
    "\n",
    "plt.savefig('synthetic_random_linear_true_distance_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff1dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "reconstruction_matrix = test_pred_distances[GRAPH_TESTED*NB_BINS:GRAPH_TESTED*NB_BINS+NB_BINS, :]\n",
    "axs.imshow(reconstruction_matrix, cmap='hot', interpolation='nearest')\n",
    "axs.tick_params(axis='both', which='major', labelsize=30, width=4)\n",
    "\n",
    "plt.savefig('synthetic_random_linear_pred_distance_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab04dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "error = (reconstruction_matrix - ground_truth_matrix)**2\n",
    "print(np.mean(error))\n",
    "axs.imshow(error, cmap='hot', interpolation='nearest')\n",
    "axs.tick_params(axis='both', which='major', labelsize=30, width=4)\n",
    "\n",
    "plt.savefig('synthetic_random_linear_error_distance_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89fbc7",
   "metadata": {},
   "source": [
    "### Test latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50, 50))\n",
    "\n",
    "test_true_structure = test_true_structures[GRAPH_TESTED]\n",
    "test_pred_structure = test_pred_structures[GRAPH_TESTED]\n",
    "\n",
    "test_pred_structure_superposed, test_true_structure_superposed = \\\n",
    "        kabsch_superimposition_numpy(test_pred_structure, test_true_structure)\n",
    "\n",
    "x_pred = test_pred_structure_superposed[:, 0]  \n",
    "y_pred = test_pred_structure_superposed[:, 1]\n",
    "z_pred = test_pred_structure_superposed[:, 2]\n",
    "\n",
    "x_true = test_true_structure_superposed[:, 0]  \n",
    "y_true = test_true_structure_superposed[:, 1]\n",
    "z_true = test_true_structure_superposed[:, 2]\n",
    "\n",
    "# Initialize figure with 4 3D subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]])\n",
    "\n",
    "# adding surfaces to subplots.\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=x_true, y=y_true, z=z_true,\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=np.asarray(range(len(x_true))),\n",
    "        colorscale='Viridis',\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=x_pred, y=y_pred, z=z_pred,\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=np.asarray(range(len(x_pred))),\n",
    "        colorscale='Viridis',\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "),row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Shape comparison\n",
    "print('Kabsch distance is ' + str(kabsch_distance_numpy(test_pred_structure, test_true_structure)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bf39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_structure = test_pred_structure_superposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32007799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure with 3D subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{'type': 'scatter3d'}]])\n",
    "\n",
    "# adding surfaces to subplots.\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=display_structure[:,0], y=display_structure[:,1], z=display_structure[:,2], opacity=0.7,\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=np.asarray(range(len(display_structure[:,0]))),\n",
    "        colorscale='Viridis',\n",
    "        line=dict(width=3)\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524962bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trussart predicted structure\n",
    "torch_trussart_hic = torch.FloatTensor(trussart_hic)\n",
    "torch_trussart_hic = torch.reshape(torch_trussart_hic, (1, NB_BINS, NB_BINS))\n",
    "torch_trussart_hic = torch.repeat_interleave(torch_trussart_hic, BATCH_SIZE, 0)\n",
    "\n",
    "trussart_pred_structure, trussart_pred_distance = model(torch_trussart_hic)\n",
    "trussart_pred_structure = trussart_pred_structure.detach().numpy()[0]\n",
    "trussart_pred_distance = trussart_pred_distance.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for true_structure in trussart_structures:\n",
    "    distances.append(kabsch_distance_numpy(trussart_pred_structure, true_structure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450f9ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Best match Trussart structure\n",
    "best_match_trussart_true_structure = trussart_structures[np.argmin(distances)]\n",
    "\n",
    "# Superpose structure using Kabsch algorithm\n",
    "trussart_pred_structure_superposed, trussart_true_structure_superposed = \\\n",
    "        kabsch_superimposition_numpy(trussart_pred_structure, best_match_trussart_true_structure)\n",
    "\n",
    "# Plot and compare the two structures\n",
    "x_pred = trussart_pred_structure_superposed[:, 0]  \n",
    "y_pred = trussart_pred_structure_superposed[:, 1]\n",
    "z_pred = trussart_pred_structure_superposed[:, 2]\n",
    "\n",
    "x_true = trussart_true_structure_superposed[:, 0]  \n",
    "y_true = trussart_true_structure_superposed[:, 1]\n",
    "z_true = trussart_true_structure_superposed[:, 2]\n",
    "\n",
    "# Initialize figure with 4 3D subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]])\n",
    "\n",
    "# adding surfaces to subplots.\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=x_true, y=y_true, z=z_true,\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=np.asarray(range(len(x_true))),\n",
    "        colorscale='Viridis',\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=x_pred, y=y_pred, z=z_pred,\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=np.asarray(range(len(x_pred))),\n",
    "        colorscale='Viridis',\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "),row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_structure = trussart_pred_structure_superposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure with 3D subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{'type': 'scatter3d'}]])\n",
    "\n",
    "# adding surfaces to subplots.\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=display_structure[:,0], y=display_structure[:,1], z=display_structure[:,2], opacity=0.7,\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=np.asarray(range(len(display_structure[:,0]))),\n",
    "        colorscale='Viridis',\n",
    "        line=dict(width=3)\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a384499",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "axs.imshow(trussart_hic, cmap='hot', interpolation='nearest')\n",
    "axs.tick_params(axis='both', which='major', labelsize=30, width=4)\n",
    "\n",
    "plt.savefig('trussart_hic_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10dfa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "axs.imshow(trussart_pred_distance, cmap='hot', interpolation='nearest')\n",
    "axs.tick_params(axis='both', which='major', labelsize=30, width=4)\n",
    "\n",
    "plt.savefig('treach3d_distance_matrix_on_trussart.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ee731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(kabsch_distances, 100, facecolor='blue', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "print('min: ' + str(np.min(kabsch_distances)))\n",
    "print('mean: ' + str(np.mean(kabsch_distances)))\n",
    "print('median: ' + str(np.median(kabsch_distances)))\n",
    "print('variance: ' + str(np.var(kabsch_distances)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087512c4",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf116416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS_ROOT = '../../../../results/non_ae/synthetic_random/linear/'\n",
    "# LAMBDA_CONFIGURATION = str(LAMBDA_KABSCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(RESULTS_ROOT + 'non_ae_synthetic_random_linear_losses_50_' + LAMBDA_CONFIGURATION + '.txt', losses)\n",
    "\n",
    "# np.savetxt(RESULTS_ROOT + 'non_ae_synthetic_random_linear_train_kabsch_losses_all_epochs_50_' + \n",
    "#            LAMBDA_CONFIGURATION + '.txt', train_kabsch_losses_all_epochs)\n",
    "# np.savetxt(RESULTS_ROOT + 'non_ae_synthetic_random_linear_test_kabsch_losses_all_epochs_50_' + \n",
    "#            LAMBDA_CONFIGURATION + '.txt', test_kabsch_losses_all_epochs)\n",
    "\n",
    "# np.savetxt(RESULTS_ROOT + 'non_ae_synthetic_random_linear_train_distance_losses_all_epochs_50_' +\n",
    "#            LAMBDA_CONFIGURATION + '.txt', train_distance_losses_all_epochs)\n",
    "# np.savetxt(RESULTS_ROOT + 'non_ae_synthetic_random_linear_test_distance_losses_all_epochs_50_' + \n",
    "#            LAMBDA_CONFIGURATION + '.txt', test_distance_losses_all_epochs)\n",
    "\n",
    "# np.savetxt(RESULTS_ROOT + 'non_ae_synthetic_random_linear_trussart_test_kabsch_losses_all_epochs_50_' +\n",
    "#                LAMBDA_CONFIGURATION + '.txt', trussart_test_kabsch_losses_all_epochs)\n",
    "# np.savetxt(RESULTS_ROOT + 'non_ae_synthetic_random_linear_trussart_test_structure_50_' +\n",
    "#                LAMBDA_CONFIGURATION + '.txt', trussart_pred_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24e4a5",
   "metadata": {},
   "source": [
    "# Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \n",
    "#            '../../../../models/non_ae/synthetic_random/linear/non_ae_synthetic_random_linear_model_50_' \n",
    "#            + LAMBDA_CONFIGURATION + '.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

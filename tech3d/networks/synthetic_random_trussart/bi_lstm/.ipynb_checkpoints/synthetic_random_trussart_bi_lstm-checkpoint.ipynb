{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "educated-boxing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:38.764663Z",
     "start_time": "2021-09-13T09:11:35.856829Z"
    }
   },
   "outputs": [],
   "source": [
    "# File processing\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data display \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "# Machine learning\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import linalg as LAtorch\n",
    "from numpy import linalg as LAnumpy\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "# Setting device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac13c5",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465431e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:38.769229Z",
     "start_time": "2021-09-13T09:11:38.766502Z"
    }
   },
   "outputs": [],
   "source": [
    "NB_EPOCHS = 10\n",
    "BATCH_SIZE = 10\n",
    "NB_BINS = 202\n",
    "EMBEDDING_SIZE = 3 # Euclidean 3D space\n",
    "LEARNING_RATE = 0.001\n",
    "SEED = 0\n",
    "LAMBDA_KABSCH = 0.1\n",
    "TRAIN_DATASET_SIZE = 800\n",
    "TEST_DATASET_SIZE = 200\n",
    "\n",
    "# Trussart analysis dataset constants\n",
    "TRUSSART_HIC_PATH = '../../../../experiments/data/trussart/hic_matrices/150_TADlike_alpha_150_set0.mat'\n",
    "TRUSSART_STRUCTURES_PATH = '../../../../experiments/data/trussart/structure_matrices/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc7277",
   "metadata": {},
   "source": [
    "# Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26605809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:38.777895Z",
     "start_time": "2021-09-13T09:11:38.773515Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b9e57c",
   "metadata": {},
   "source": [
    "# Trussart analysis dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d412f446",
   "metadata": {},
   "source": [
    "## Hic matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naval-commons",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:38.801514Z",
     "start_time": "2021-09-13T09:11:38.779540Z"
    }
   },
   "outputs": [],
   "source": [
    "trussart_hic = np.loadtxt(TRUSSART_HIC_PATH, dtype='f', delimiter='\\t')\n",
    "scaler = MinMaxScaler()\n",
    "trussart_hic = scaler.fit_transform(trussart_hic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b876b",
   "metadata": {},
   "source": [
    "## Structure matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43eefd71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:38.985243Z",
     "start_time": "2021-09-13T09:11:38.804263Z"
    }
   },
   "outputs": [],
   "source": [
    "trussart_structures = []\n",
    "\n",
    "file_list = os.listdir(TRUSSART_STRUCTURES_PATH)\n",
    "file_list = filter(lambda f: f.endswith('.xyz'), file_list)\n",
    "\n",
    "for file_name in file_list:\n",
    "    current_trussart_structure = np.loadtxt(TRUSSART_STRUCTURES_PATH + file_name, dtype='f', delimiter='\\t')\n",
    "    current_trussart_structure = current_trussart_structure[:,1:]\n",
    "    trussart_structures.append(current_trussart_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-gnome",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debceb14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:38.988464Z",
     "start_time": "2021-09-13T09:11:38.986439Z"
    }
   },
   "outputs": [],
   "source": [
    "# grab last 4 digits of the file txt name:\n",
    "def last_4digits(x):\n",
    "    return(x[-8:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f940d71",
   "metadata": {},
   "source": [
    "### Hic matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b3ecaf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:38.994276Z",
     "start_time": "2021-09-13T09:11:38.991484Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transfer_learning_hics = []\n",
    "\n",
    "file_list = os.listdir('../../../data/synthetic_random_trussart/train/hic_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_train_transfer_learning_hic = np.loadtxt('../../../data/synthetic_random_trussart/train/hic_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    train_transfer_learning_hics.append(current_train_transfer_learning_hic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3704005f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:38.999599Z",
     "start_time": "2021-09-13T09:11:38.996535Z"
    }
   },
   "outputs": [],
   "source": [
    "test_transfer_learning_hics = []\n",
    "\n",
    "file_list = os.listdir('../../../data/synthetic_random_trussart/test/hic_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_test_transfer_learning_hic = np.loadtxt('../../../data/synthetic_random_trussart/test/hic_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    test_transfer_learning_hics.append(current_test_transfer_learning_hic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc28650",
   "metadata": {},
   "source": [
    "### Structure matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f6f853c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.003942Z",
     "start_time": "2021-09-13T09:11:39.001164Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transfer_learning_structures = []\n",
    "\n",
    "file_list = os.listdir('../../../data/synthetic_random_trussart/train/structure_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_train_transfer_learning_structure = \\\n",
    "        np.loadtxt('../../../data/synthetic_random_trussart/train/structure_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    train_transfer_learning_structures.append(current_train_transfer_learning_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a41608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.008651Z",
     "start_time": "2021-09-13T09:11:39.005409Z"
    }
   },
   "outputs": [],
   "source": [
    "test_transfer_learning_structures = []\n",
    "\n",
    "file_list = os.listdir('../../../data/synthetic_random_trussart/test/structure_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_test_transfer_learning_structure = \\\n",
    "        np.loadtxt('../../../data/synthetic_random_trussart/test/structure_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    test_transfer_learning_structures.append(current_test_transfer_learning_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24328a71",
   "metadata": {},
   "source": [
    "### Distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "182f8783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.013078Z",
     "start_time": "2021-09-13T09:11:39.010219Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transfer_learning_distances = []\n",
    "\n",
    "file_list = os.listdir('../../../data/synthetic_random_trussart/train/distance_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_train_transfer_learning_distance = \\\n",
    "            np.loadtxt('../../../data/synthetic_random_trussart/train/distance_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    train_transfer_learning_distances.append(current_train_transfer_learning_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeebfaa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.017233Z",
     "start_time": "2021-09-13T09:11:39.014291Z"
    }
   },
   "outputs": [],
   "source": [
    "test_transfer_learning_distances = []\n",
    "\n",
    "file_list = os.listdir('../../../data/synthetic_random_trussart/test/distance_matrices/')\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith('.txt'), file_list), key = last_4digits):\n",
    "    current_test_transfer_learning_distance = \\\n",
    "            np.loadtxt('../../../data/synthetic_random_trussart/test/distance_matrices/'\\\n",
    "                                                     + file_name, dtype='f', delimiter=' ')\n",
    "    test_transfer_learning_distances.append(current_test_transfer_learning_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0a949",
   "metadata": {},
   "source": [
    "### Final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cfddc",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ecf83d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.022020Z",
     "start_time": "2021-09-13T09:11:39.019934Z"
    }
   },
   "outputs": [],
   "source": [
    "is_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regulation-terrain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.030619Z",
     "start_time": "2021-09-13T09:11:39.023730Z"
    }
   },
   "outputs": [],
   "source": [
    "class VanillaDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(VanillaDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        if is_training:\n",
    "            return ['synthetic_random_trussart_bi_lstm_train_data.txt']\n",
    "        else:\n",
    "            return ['synthetic_random_trussart_bi_lstm_test_data.txt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "        if is_training:\n",
    "            dataset_size = TRAIN_DATASET_SIZE\n",
    "        else:\n",
    "            dataset_size = TEST_DATASET_SIZE\n",
    "        \n",
    "        for i in tqdm(range(dataset_size)):\n",
    "            \n",
    "            if is_training:\n",
    "                transfer_learning_hic = train_transfer_learning_hics[i]\n",
    "                transfer_learning_structure = train_transfer_learning_structures[i]\n",
    "                transfer_learning_distance_matrix = train_transfer_learning_distances[i]\n",
    "            else:\n",
    "                transfer_learning_hic = test_transfer_learning_hics[i]\n",
    "                transfer_learning_structure = test_transfer_learning_structures[i]\n",
    "                transfer_learning_distance_matrix = test_transfer_learning_distances[i]\n",
    "               \n",
    "            hic_matrix = torch.FloatTensor(transfer_learning_hic)\n",
    "            structure_matrix = torch.FloatTensor(transfer_learning_structure)\n",
    "            distance_matrix = torch.FloatTensor(transfer_learning_distance_matrix)\n",
    "\n",
    "            data = Data(hic_matrix=hic_matrix, structure_matrix=structure_matrix, distance_matrix=distance_matrix)\n",
    "            data_list.append(data)\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incredible-reform",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.344102Z",
     "start_time": "2021-09-13T09:11:39.032537Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e86f0188efa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVanillaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-3bb010be83b3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVanillaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVanillaDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     52\u001b[0m     def __init__(self, root=None, transform=None, pre_transform=None,\n\u001b[1;32m     53\u001b[0m                  pre_filter=None):\n\u001b[0;32m---> 54\u001b[0;31m         super(InMemoryDataset, self).__init__(root, transform, pre_transform,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                               pre_filter)\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'process'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pre_transform.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-3bb010be83b3>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mtransfer_learning_hic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transfer_learning_hics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mtransfer_learning_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transfer_learning_structures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtransfer_learning_distance_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transfer_learning_distances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_dataset = VanillaDataset('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-wealth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.350967Z",
     "start_time": "2021-09-13T09:11:35.882Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = len(train_dataset)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9ec12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.352372Z",
     "start_time": "2021-09-13T09:11:35.883Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6adbb",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45875f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.354417Z",
     "start_time": "2021-09-13T09:11:35.885Z"
    }
   },
   "outputs": [],
   "source": [
    "is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd917ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.356112Z",
     "start_time": "2021-09-13T09:11:35.886Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = VanillaDataset('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6319b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.357822Z",
     "start_time": "2021-09-13T09:11:35.887Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = len(test_dataset)\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede05c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.359341Z",
     "start_time": "2021-09-13T09:11:35.889Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-invite",
   "metadata": {},
   "source": [
    "# Bi-LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a7e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.360854Z",
     "start_time": "2021-09-13T09:11:35.891Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.lstm_encoder = torch.nn.LSTM(NB_BINS, EMBEDDING_SIZE, batch_first=True, bidirectional=True)\n",
    "        self.nn_encoder = torch.nn.Linear(2*EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        \n",
    "        # Initialization\n",
    "        self.xavier_initializer(self.lstm_encoder)\n",
    "        \n",
    "    def forward(self, x, is_training=False):\n",
    "        \n",
    "        x = torch.reshape(x, (BATCH_SIZE, NB_BINS, NB_BINS))\n",
    "        \n",
    "        # Encoder\n",
    "        z, (h, c) = self.lstm_encoder(x)\n",
    "        z = self.nn_encoder(z)\n",
    "        \n",
    "        # Structure space\n",
    "        z = centralize_and_normalize_torch(z)\n",
    "        \n",
    "        # Distance space\n",
    "        w = torch.cdist(z, z, p=2)\n",
    "        \n",
    "        return z, w\n",
    "    \n",
    "    def xavier_initializer(self, module):\n",
    "        \n",
    "        for name, param in module.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                torch.nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                torch.nn.init.xavier_normal_(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771473b",
   "metadata": {},
   "source": [
    "# Structure analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74381471",
   "metadata": {},
   "source": [
    "### Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db24cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.362496Z",
     "start_time": "2021-09-13T09:11:35.892Z"
    }
   },
   "outputs": [],
   "source": [
    "def centralize_torch(z):\n",
    "    return z - torch.repeat_interleave(torch.reshape(torch.mean(z, axis=1), (-1,1,EMBEDDING_SIZE)), NB_BINS, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056afa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.364056Z",
     "start_time": "2021-09-13T09:11:35.894Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_torch(z):\n",
    "    \n",
    "    norms = LAtorch.norm(z, 2, dim=2)\n",
    "    max_norms, _ = torch.max(norms, axis=1)\n",
    "    max_norms = torch.reshape(max_norms, (BATCH_SIZE,1,1))\n",
    "    max_norms = torch.repeat_interleave(max_norms, NB_BINS, dim=1)\n",
    "    max_norms = torch.repeat_interleave(max_norms, EMBEDDING_SIZE, dim=2)\n",
    "    max_norms[max_norms == 0] = 1\n",
    "    \n",
    "    return z / max_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06874f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.365477Z",
     "start_time": "2021-09-13T09:11:35.895Z"
    }
   },
   "outputs": [],
   "source": [
    "def centralize_and_normalize_torch(z):\n",
    "    \n",
    "    # Translate\n",
    "    z = centralize_torch(z)\n",
    "    \n",
    "    # Scale\n",
    "    z = normalize_torch(z)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e764b0",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30307ac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.368216Z",
     "start_time": "2021-09-13T09:11:35.896Z"
    }
   },
   "outputs": [],
   "source": [
    "def centralize_numpy(z):\n",
    "    return z - np.mean(z, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688fb4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.381822Z",
     "start_time": "2021-09-13T09:11:35.898Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_numpy(z):\n",
    "    \n",
    "    norm = LAnumpy.norm(z, 2, axis=1)\n",
    "    max_norm = np.max(norm, axis=0)\n",
    "    if max_norm == 0:\n",
    "        max_norm = 1\n",
    "    \n",
    "    return z / max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f22cfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.399831Z",
     "start_time": "2021-09-13T09:11:35.899Z"
    }
   },
   "outputs": [],
   "source": [
    "def centralize_and_normalize_numpy(z):\n",
    "    \n",
    "    # Translate\n",
    "    z = centralize_numpy(z)\n",
    "    \n",
    "    # Scale\n",
    "    z = normalize_numpy(z)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885c245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.408036Z",
     "start_time": "2021-09-13T09:11:35.900Z"
    }
   },
   "outputs": [],
   "source": [
    "def kabsch_superimposition_numpy(pred_structure, true_structure):\n",
    "    \n",
    "    # Centralize and normalize to unit ball\n",
    "    pred_structure_unit_ball = centralize_and_normalize_numpy(pred_structure)\n",
    "    true_structure_unit_ball = centralize_and_normalize_numpy(true_structure)\n",
    "    \n",
    "    # Rotation (solution for the constrained orthogonal Procrustes problem, subject to det(R) = 1)\n",
    "    m = np.matmul(np.transpose(true_structure_unit_ball), pred_structure_unit_ball)\n",
    "    u, s, vh = np.linalg.svd(m)\n",
    "    \n",
    "    d = np.sign(np.linalg.det(np.matmul(u, vh)))\n",
    "    a = np.eye(EMBEDDING_SIZE)\n",
    "    a[-1,-1] = d\n",
    "    \n",
    "    r = np.matmul(np.matmul(u, a), vh)\n",
    "    \n",
    "    pred_structure_unit_ball = np.transpose(np.matmul(r, np.transpose(pred_structure_unit_ball)))\n",
    "    \n",
    "    return pred_structure_unit_ball, true_structure_unit_ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18470850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.417507Z",
     "start_time": "2021-09-13T09:11:35.901Z"
    }
   },
   "outputs": [],
   "source": [
    "def kabsch_distance_numpy(pred_structure, true_structure):\n",
    "    \n",
    "    pred_structure_unit_ball, true_structure_unit_ball = kabsch_superimposition_numpy(pred_structure, true_structure)\n",
    "    \n",
    "    # Structure comparison\n",
    "    d = np.mean(np.sum(np.square(pred_structure_unit_ball - true_structure_unit_ball), axis=1))\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245fb73",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9f1eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.423269Z",
     "start_time": "2021-09-13T09:11:35.903Z"
    }
   },
   "outputs": [],
   "source": [
    "def kabsch_loss_fct(pred_structure, true_structure):\n",
    "    \n",
    "    # NOTE: the two input structures should already be centralized and normalized\n",
    "    \n",
    "    m = torch.matmul(torch.transpose(true_structure, 1, 2), pred_structure)\n",
    "    u, s, vh = torch.linalg.svd(m)\n",
    "    \n",
    "    d = torch.sign(torch.linalg.det(torch.matmul(u, vh)))\n",
    "    a = torch.eye(EMBEDDING_SIZE).reshape((1, EMBEDDING_SIZE, EMBEDDING_SIZE)).repeat_interleave(BATCH_SIZE, dim=0)\n",
    "    a[:,-1,-1] = d\n",
    "    \n",
    "    r = torch.matmul(torch.matmul(u, a), vh)\n",
    "    \n",
    "    pred_structure = torch.transpose(torch.matmul(r, torch.transpose(pred_structure, 1, 2)), 1, 2)\n",
    "    \n",
    "    return torch.mean(torch.sum(torch.square(pred_structure - true_structure), axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3a72a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.425008Z",
     "start_time": "2021-09-13T09:11:35.904Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_loss_fct = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2b16d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.427003Z",
     "start_time": "2021-09-13T09:11:35.905Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_trussart_test_kabsch_loss():\n",
    "    \n",
    "    torch_trussart_hic = torch.FloatTensor(trussart_hic)\n",
    "    torch_trussart_hic = torch.reshape(torch_trussart_hic, (1, NB_BINS, NB_BINS))\n",
    "    torch_trussart_hic = torch.repeat_interleave(torch_trussart_hic, BATCH_SIZE, 0)\n",
    "    \n",
    "    trussart_pred_structure, _ = model(torch_trussart_hic)\n",
    "    trussart_pred_structure = trussart_pred_structure.detach().numpy()[0]\n",
    "    \n",
    "    kabsch_distances = []\n",
    "    for true_structure in trussart_structures:\n",
    "        kabsch_distances.append(kabsch_distance_numpy(trussart_pred_structure, true_structure))\n",
    "        \n",
    "    return np.mean(kabsch_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-prerequisite",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-christianity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.438637Z",
     "start_time": "2021-09-13T09:11:35.907Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b37ecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.440412Z",
     "start_time": "2021-09-13T09:11:35.909Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.legend([matplotlib.lines.Line2D([0], [0], color=\"c\", lw=4),\n",
    "                matplotlib.lines.Line2D([0], [0], color=\"b\", lw=4),\n",
    "                matplotlib.lines.Line2D([0], [0], color=\"k\", lw=4)], \n",
    "               ['max-gradient', 'mean-gradient', 'zero-gradient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-terry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.443069Z",
     "start_time": "2021-09-13T09:11:35.911Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_structure, pred_distance = model(data.hic_matrix)\n",
    "        \n",
    "        true_hic = data.hic_matrix.to(device)\n",
    "        \n",
    "        true_structure = data.structure_matrix.to(device)\n",
    "        true_structure = torch.reshape(true_structure, (BATCH_SIZE, NB_BINS, EMBEDDING_SIZE))\n",
    "        \n",
    "        pred_distance = torch.reshape(pred_distance, (BATCH_SIZE*NB_BINS, NB_BINS))\n",
    "        true_distance = data.distance_matrix.to(device)\n",
    "        \n",
    "        # Kabsch loss\n",
    "        kabsch_loss = kabsch_loss_fct(pred_structure, true_structure)\n",
    "        \n",
    "        # Distance loss \n",
    "        distance_loss = distance_loss_fct(pred_distance, true_distance)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = LAMBDA_KABSCH * kabsch_loss + distance_loss\n",
    "        \n",
    "#         with torch.autograd.detect_anomaly():\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        \n",
    "        # Plot grad flow\n",
    "#         plot_grad_flow(model.named_parameters())\n",
    "        \n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-excess",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.444774Z",
     "start_time": "2021-09-13T09:11:35.912Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    true_hics = []\n",
    "    \n",
    "    pred_structures = []\n",
    "    true_structures = []\n",
    "    \n",
    "    pred_distances = []\n",
    "    true_distances = []\n",
    "    \n",
    "    kabsch_losses = []\n",
    "    distance_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            \n",
    "            pred_structure, pred_distance = model(data.hic_matrix)\n",
    "            \n",
    "            pred_structure = pred_structure.detach().cpu()\n",
    "            pred_distance = pred_distance.detach().cpu()\n",
    "            \n",
    "            pred_distance = torch.reshape(pred_distance, (BATCH_SIZE*NB_BINS, NB_BINS))\n",
    "            \n",
    "            true_hic = data.hic_matrix.detach().cpu()\n",
    "            true_structure = data.structure_matrix.detach().cpu()\n",
    "            true_distance = data.distance_matrix.detach().cpu()\n",
    "            \n",
    "            true_structure = torch.reshape(true_structure, (BATCH_SIZE, NB_BINS, EMBEDDING_SIZE))\n",
    "            \n",
    "            # Kabsch loss\n",
    "            kabsch_loss = kabsch_loss_fct(pred_structure, true_structure).numpy()\n",
    "            kabsch_losses.append(kabsch_loss)\n",
    "            \n",
    "            # Distance \n",
    "            distance_loss = distance_loss_fct(pred_distance, true_distance).numpy()\n",
    "            distance_losses.append(distance_loss)\n",
    "            \n",
    "            # To numpy\n",
    "            true_hic = true_hic.numpy()\n",
    "            \n",
    "            pred_structure = pred_structure.numpy()\n",
    "            true_structure = true_structure.numpy()\n",
    "            \n",
    "            pred_distance = pred_distance.numpy()\n",
    "            true_distance = true_distance.numpy()\n",
    "            \n",
    "            # Store results\n",
    "            true_hics.append(true_hic)\n",
    "            \n",
    "            pred_structures.append(pred_structure)\n",
    "            true_structures.append(true_structure)\n",
    "            \n",
    "            pred_distances.append(pred_distance)\n",
    "            true_distances.append(true_distance)\n",
    "    \n",
    "    # Format results\n",
    "    true_hics = np.vstack(true_hics)\n",
    "    \n",
    "    pred_structures = np.vstack(pred_structures)\n",
    "    true_structures = np.vstack(true_structures)\n",
    "    \n",
    "    pred_distances = np.vstack(pred_distances)\n",
    "    true_distances = np.vstack(true_distances)\n",
    "    \n",
    "    # Compute mean losses\n",
    "    mean_kabsch_loss = np.mean(np.asarray(kabsch_losses).flatten())\n",
    "    mean_distance_loss = np.mean(np.asarray(distance_losses).flatten())\n",
    "    \n",
    "    \n",
    "    return mean_kabsch_loss, mean_distance_loss, true_hics, \\\n",
    "            pred_structures, true_structures, pred_distances, true_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-schedule",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.446094Z",
     "start_time": "2021-09-13T09:11:35.913Z"
    }
   },
   "outputs": [],
   "source": [
    "train_kabsch_losses_all_epochs = []\n",
    "train_distance_losses_all_epochs = []\n",
    "\n",
    "test_kabsch_losses_all_epochs = []\n",
    "test_distance_losses_all_epochs = []\n",
    "\n",
    "losses = []\n",
    "\n",
    "trussart_test_kabsch_losses_all_epochs = []\n",
    "\n",
    "for epoch in range(1, NB_EPOCHS+1):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    \n",
    "    ### Training\n",
    "    train_mean_kabsch_loss, train_mean_distance_loss, train_true_hics, \\\n",
    "        train_pred_structures, train_true_structures, train_pred_distances, \\\n",
    "            train_true_distances = evaluate(train_loader) \n",
    "    \n",
    "    # Store results\n",
    "    train_kabsch_losses_all_epochs.append(train_mean_kabsch_loss)    \n",
    "    train_distance_losses_all_epochs.append(train_mean_distance_loss)\n",
    "    \n",
    "    ### Testing\n",
    "    test_mean_kabsch_loss, test_mean_distance_loss, test_true_hics, \\\n",
    "        test_pred_structures, test_true_structures, test_pred_distances, \\\n",
    "            test_true_distances = evaluate(test_loader) \n",
    "    \n",
    "    ### Trussart test\n",
    "    trussart_test_kabsch_loss = compute_trussart_test_kabsch_loss()\n",
    "    \n",
    "    # Store results\n",
    "    test_kabsch_losses_all_epochs.append(test_mean_kabsch_loss)    \n",
    "    test_distance_losses_all_epochs.append(test_mean_distance_loss)\n",
    "    \n",
    "    trussart_test_kabsch_losses_all_epochs.append(trussart_test_kabsch_loss)\n",
    "    \n",
    "    print('E: {:03d}, Tr K: {:.4f}, Tr D: {:.4f}, Te K: {:.4f}, Te D: {:.4f}, Trus K: {:.4f}'.format(\\\n",
    "        epoch, train_mean_kabsch_loss, train_mean_distance_loss, \\\n",
    "            test_mean_kabsch_loss, test_mean_distance_loss, trussart_test_kabsch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfeae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.447291Z",
     "start_time": "2021-09-13T09:11:35.915Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses, label='Losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6c2b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.448745Z",
     "start_time": "2021-09-13T09:11:35.916Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_kabsch_losses_all_epochs, label='Train Kabsch')\n",
    "plt.plot(test_kabsch_losses_all_epochs, label='Test Kabsch')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0b665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.450243Z",
     "start_time": "2021-09-13T09:11:35.917Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_distance_losses_all_epochs, label='Train Dist')\n",
    "plt.plot(test_distance_losses_all_epochs, label='Test Dist')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c08d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.451601Z",
     "start_time": "2021-09-13T09:11:35.919Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(trussart_test_kabsch_losses_all_epochs, label='Test Trussart Kabsch')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52a3fb",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6299a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.453184Z",
     "start_time": "2021-09-13T09:11:35.920Z"
    }
   },
   "outputs": [],
   "source": [
    "GRAPH_TESTED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f29f0",
   "metadata": {},
   "source": [
    "### Test distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55267a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.454413Z",
     "start_time": "2021-09-13T09:11:35.922Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15,15))\n",
    "\n",
    "ground_truth_matrix = test_true_distances[GRAPH_TESTED*NB_BINS:GRAPH_TESTED*NB_BINS+NB_BINS, :]\n",
    "axes[0].imshow(ground_truth_matrix, cmap='hot', interpolation='nearest')\n",
    "\n",
    "reconstruction_matrix = test_pred_distances[GRAPH_TESTED*NB_BINS:GRAPH_TESTED*NB_BINS+NB_BINS, :]\n",
    "axes[1].imshow(reconstruction_matrix, cmap='hot', interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89fbc7",
   "metadata": {},
   "source": [
    "### Test latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd48d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.455732Z",
     "start_time": "2021-09-13T09:11:35.924Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50, 50))\n",
    "\n",
    "test_true_structure = test_true_structures[GRAPH_TESTED]\n",
    "test_pred_structure = test_pred_structures[GRAPH_TESTED]\n",
    "\n",
    "test_pred_structure_superposed, test_true_structure_superposed = \\\n",
    "        kabsch_superimposition_numpy(test_pred_structure, test_true_structure)\n",
    "\n",
    "x_pred = test_pred_structure_superposed[:, 0]  \n",
    "y_pred = test_pred_structure_superposed[:, 1]\n",
    "z_pred = test_pred_structure_superposed[:, 2]\n",
    "\n",
    "x_true = test_true_structure_superposed[:, 0]  \n",
    "y_true = test_true_structure_superposed[:, 1]\n",
    "z_true = test_true_structure_superposed[:, 2]\n",
    "\n",
    "# Initialize figure with 4 3D subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]])\n",
    "\n",
    "# adding surfaces to subplots.\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=x_true, y=y_true, z=z_true,\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=np.asarray(range(len(x_true))),\n",
    "        colorscale='Viridis',\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=x_pred, y=y_pred, z=z_pred,\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=np.asarray(range(len(x_pred))),\n",
    "        colorscale='Viridis',\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "),row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Shape comparison\n",
    "print('Kabsch distance is ' + str(kabsch_distance_numpy(test_pred_structure, test_true_structure)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf00f1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.456807Z",
     "start_time": "2021-09-13T09:11:35.925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trussart perfect structure\n",
    "trussart_true_structure = np.mean(trussart_structures, axis=0)\n",
    "\n",
    "# Trussart predicted structure\n",
    "torch_trussart_hic = torch.FloatTensor(trussart_hic)\n",
    "torch_trussart_hic = torch.reshape(torch_trussart_hic, (1, NB_BINS, NB_BINS))\n",
    "torch_trussart_hic = torch.repeat_interleave(torch_trussart_hic, BATCH_SIZE, 0)\n",
    "\n",
    "trussart_pred_structure, _ = model(torch_trussart_hic)\n",
    "trussart_pred_structure = trussart_pred_structure.detach().numpy()[0]\n",
    "\n",
    "# Superpose structure using Kabsch algorithm\n",
    "trussart_pred_structure_superposed, trussart_true_structure_superposed = \\\n",
    "        kabsch_superimposition_numpy(trussart_pred_structure, trussart_true_structure)\n",
    "\n",
    "# Plot and compare the two structures\n",
    "x_pred = trussart_pred_structure_superposed[:, 0]  \n",
    "y_pred = trussart_pred_structure_superposed[:, 1]\n",
    "z_pred = trussart_pred_structure_superposed[:, 2]\n",
    "\n",
    "x_true = trussart_true_structure_superposed[:, 0]  \n",
    "y_true = trussart_true_structure_superposed[:, 1]\n",
    "z_true = trussart_true_structure_superposed[:, 2]\n",
    "\n",
    "# Initialize figure with 4 3D subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]])\n",
    "\n",
    "# adding surfaces to subplots.\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=x_true, y=y_true, z=z_true,\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=np.asarray(range(len(x_true))),\n",
    "        colorscale='Viridis',\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "    x=x_pred, y=y_pred, z=z_pred,\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=np.asarray(range(len(x_pred))),\n",
    "        colorscale='Viridis',\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='darkblue',\n",
    "        width=2\n",
    "    )\n",
    "),row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c97ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.457929Z",
     "start_time": "2021-09-13T09:11:35.927Z"
    }
   },
   "outputs": [],
   "source": [
    "kabsch_distances = []\n",
    "\n",
    "for graph_index in range(test_size):\n",
    "\n",
    "    test_true_structure = test_true_structures[graph_index,:,:]\n",
    "    test_pred_structure = test_pred_structures[graph_index,:,:]\n",
    "    \n",
    "    d = kabsch_distance_numpy(test_pred_structure, test_true_structure)\n",
    "    kabsch_distances.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ee731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.458891Z",
     "start_time": "2021-09-13T09:11:35.928Z"
    }
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(kabsch_distances, 100, facecolor='blue', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "print('mean: ' + str(np.mean(kabsch_distances)))\n",
    "print('median: ' + str(np.median(kabsch_distances)))\n",
    "print('variance: ' + str(np.var(kabsch_distances)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb6a1b",
   "metadata": {},
   "source": [
    "# Save test losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc257e2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.460181Z",
     "start_time": "2021-09-13T09:11:35.930Z"
    }
   },
   "outputs": [],
   "source": [
    "RESULTS_ROOT = '../../../results/synthetic_random_trussart/bi_lstm/'\n",
    "LAMBDA_CONFIGURATION = str(LAMBDA_KABSCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165acd7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.461459Z",
     "start_time": "2021-09-13T09:11:35.931Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(RESULTS_ROOT + 'synthetic_random_trussart_bi_lstm_losses_150_' + LAMBDA_CONFIGURATION + '.txt', losses)\n",
    "\n",
    "np.savetxt(RESULTS_ROOT + 'synthetic_random_trussart_bi_lstm_train_kabsch_losses_all_epochs_150_' + \n",
    "           LAMBDA_CONFIGURATION + '.txt', train_kabsch_losses_all_epochs)\n",
    "np.savetxt(RESULTS_ROOT + 'synthetic_random_trussart_bi_lstm_test_kabsch_losses_all_epochs_150_' + \n",
    "           LAMBDA_CONFIGURATION + '.txt', test_kabsch_losses_all_epochs)\n",
    "\n",
    "np.savetxt(RESULTS_ROOT + 'synthetic_random_trussart_bi_lstm_train_distance_losses_all_epochs_150_' +\n",
    "           LAMBDA_CONFIGURATION + '.txt', train_distance_losses_all_epochs)\n",
    "np.savetxt(RESULTS_ROOT + 'synthetic_random_trussart_bi_lstm_test_distance_losses_all_epochs_150_' + \n",
    "           LAMBDA_CONFIGURATION + '.txt', test_distance_losses_all_epochs)\n",
    "\n",
    "np.savetxt(RESULTS_ROOT + 'synthetic_random_trussart_bi_lstm_trussart_test_kabsch_losses_all_epochs_150_' +\n",
    "               LAMBDA_CONFIGURATION + '.txt', trussart_test_kabsch_losses_all_epochs)\n",
    "np.savetxt(RESULTS_ROOT + 'synthetic_random_trussart_bi_lstm_trussart_test_structure_150_' +\n",
    "               LAMBDA_CONFIGURATION + '.txt', trussart_pred_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24e4a5",
   "metadata": {},
   "source": [
    "# Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b6d1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:11:39.462541Z",
     "start_time": "2021-09-13T09:11:35.933Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, \n",
    "           '../../../models/synthetic_random/bi_lstm/synthetic_random_trussart_bi_lstm_model_lambda_150_' \n",
    "           + LAMBDA_CONFIGURATION + '.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
